version: '3'

services:

  run:
    build: miniconda-mlflow
    container_name: ${USER}-mlflow-run
    runtime: nvidia
    command: mlflow run /run
    volumes:
      - ..:/run
      - ${MLFLOW_DATA}:/mlruns
      - conda_envs:/opt/conda/envs
    depends_on:
      - server
    environment:
#     CUDA_VISIBLE_DEVICES: 0
     MLFLOW_EXPERIMENT_NAME: ${MLFLOW_EXPERIMENT_NAME}
     MLFLOW_TRACKING_URI: http://server:5000
    networks:
      - mlflow_bridge

  server:
    build: miniconda-mlflow
    container_name: ${USER}-mlflow-server
    command:
      - mlflow
      - server
      - --host
      - 0.0.0.0
      - --backend-store-uri
      - file:///mlruns
      - --default-artifact-root
      - file:///mlruns
    volumes:
      - ${MLFLOW_DATA}:/mlruns
    ports:
      - ${MLFLOW_PORT}:5000
    networks:
      - mlflow_bridge

volumes:
  conda_envs:

networks:
  mlflow_bridge:
    driver: bridge
